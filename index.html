<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Digital humanities research project exploring [your topic]">
    <meta name="author" content="Your Name">
    <title>IT Reviews | WRIT 20833</title>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <nav>
        <ul>
            <li><a href="#question">Research Question</a></li>
            <li><a href="#data">Data & Methods</a></li>
            <li><a href="#analysis">Results & Analysis</a></li>
            <li><a href="#findings">Findings</a></li>
            <li><a href="#reflection">Reflection</a></li>
        </ul>
    </nav>

    <header>
        <h1>IT Reviews</h1>
        <p>Lucy Fulghum and Reagan Nowak | WRIT 20833 | Fall 2025</p>
    </header>

    <main>
        <section id="question">
            <h2>Research Question</h2>
            <!-- TODO: Add your research question here -->
            <p>How do reviewers of IT use emotional language to process trauma? What does that reveal about horror as a cultural space for collective healing?</p>

            <p><strong>Background:</strong> This question matters because horror films occupy a unique cultural space where audiences confront fear in a controlled environment. It particularily deals with childhood trauma, bullying, and the lingering effects of fear, making it a meaningful text for exploring how people process emotionally charged experiences. Online reviews offer an unfiltered window into how viewers articulate those reactions. The observation that many reviews seemed to use emotional or trauma-related language  to reflect on personal experiences, drove this research. By analyzing these reviews computationally, we can better understand how horror films not only funtion as entertainment but also as a space for collective healing, emotional expression, and the negotiation of trauma.</p>
        </section>

        <section id="data">
            <h2>Data & Methods</h2>

            <h3>Dataset</h3>
            <!-- TODO: Describe your data collection and methodology -->
            <p><strong>Data Source:</strong> We collected data from the reviews of IT on the site IMDB.</p>
            <p><strong>Collection Method:</strong> We used instant data scrapper to collect written comments, comment titles, and rating score.</p>
            <p><strong>Dataset Size:</strong> 1,424 reviews</p>
            <p><strong>Ethical Considerations:</strong> We ensured that all data collected was publicly available and did not include any personally identifiable information.</p>

            <h3>Analysis Methods</h3>
            <p><strong>Tools:</strong> Python (pandas, VADER, Gensim)</p>
            <ul>
                <li><strong>Term Frequency Analysis:</strong> We used term frequency analysis to identify the most commonly words and phrases in the text. After preprocessing, we calculated how often each term appeared. This helped reveal the main themes and highlight which concepts the text emphasized most heavily.</li>
                <li><strong>Sentiment Analysis (VADER):</strong> We examined the overall sentiment of the text using VADER, focusing on the positive, negative, and neutral findings. We looked for patterns such as consistently positive or negative sections and changes in tone. This helped determine how the emotional content varied across the text.</li>
                <li><strong>Topic Modeling (Gensim LDA):</strong> We generated 5 topics using topic modeling. Each topic consisted of a group of related words, which revealed underlying themes from simple frequency counts. The discovered topics provided knowledge into the main subjects discussed in the text and how they are grouped together conceptually.</li>
            </ul>
        </section>

        <section id="analysis">
            <h2>Results & Analysis</h2>
            <!-- TODO: Add visualizations and code snippets -->

            <h3>Sentiment Analysis Results</h3>
            <p>Using VADER sentiment analysis, we examined the various word choice and overall tone used within those word choices. This either came out to be positive, negative, or neutral.</p>

            <!-- Single visualization with caption -->
            <figure class="viz-container">
                <img src="images/sentiment-distribution.png"
                     alt="Bar chart showing distribution of positive, negative, and neutral sentiment">
                <figcaption>Figure 1: Distribution of sentiment scores across dataset</figcaption>
            </figure>

            <h3>Code Example</h3>
            <p>Here's how I implemented the sentiment analysis using <code>vaderSentiment</code>:</p>

            <div class="code-title">sentiment_analysis.py</div>
            <pre><code>from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import pandas as pd

analyzer = SentimentIntensityAnalyzer()

# Analyze sentiment for each text
df['compound'] = df['text'].apply(
    lambda x: analyzer.polarity_scores(x)['compound']
)

# Classify sentiment
df['sentiment'] = df['compound'].apply(
    lambda x: 'positive' if x > 0.05
    else ('negative' if x < -0.05 else 'neutral')
)</code></pre>

            <h3>Topic Modeling Results</h3>
            <p>Using Gensim's LDA implementation, I identified [number] major topics...</p>

            <!-- Multiple visualizations in a grid -->
            <div class="viz-grid">
                <figure class="viz-container">
                    <img src="images/topic-model.png"
                         alt="Visualization of topic clusters from LDA analysis">
                    <figcaption>Figure 2: Topic clusters from LDA analysis</figcaption>
                </figure>

                <figure class="viz-container">
                    <img src="images/word-cloud.png"
                         alt="Word cloud showing most frequent terms">
                    <figcaption>Figure 3: Most common terms in the corpus</figcaption>
                </figure>
            </div>
        </section>

        <section id="findings">
            <h2>Key Findings</h2>
            <!-- TODO: Present your main discoveries -->

            <p>The computational analysis revealed three major insights:</p>

            <ol>
                <li><strong>Finding 1:</strong> Positive-sentiment reviews often paired empowering emotional language with trauma-related terms, such as ‚Äúface,‚Äù ‚Äústrong,‚Äù ‚Äúbrave,‚Äù or ‚Äúovercome.‚Äù This suggests that many reviewers used the film as a way to reflect on personal fears and frame their experiences in a more constructive way. </li>
                <li><strong>Finding 2:</strong> Negative-sentiment reviews showed a strong association with distress-oriented trauma language, including terms like ‚Äútriggered,‚Äù ‚Äúdisturbing,‚Äù ‚Äúpanic,‚Äù or ‚Äúunsettling.‚Äù This indicates that for some viewers, the film resurfaced unresolved fear or discomfort, reinforcing rather than easing emotional tension. </li>
                <li><strong>Finding 3:</strong> Topic modeling revealed that trauma-related language appeared across multiple themes not just in discussions of the story, but also in reviewers‚Äô reflections on their own lives. This pattern shows that horror operates as a shared cultural space where audiences connect their personal emotional histories to the narrative, using communal reviewing practices as a form of meaning-making and collective processing. </li>
            </ol>

            <h3>Detailed Results</h3>
            <p>Breaking down the sentiment distribution:</p>

            <table class="results-table">
                <thead>
                    <tr>
                        <th>Sentiment Category</th>
                        <th>Count</th>
                        <th>Percentage</th>
                        <th>Avg. Compound Score</th>
                    </tr>
                </thead>
                <tbody>
                    <tr class="highlight">
                        <td>Positive</td>
                        <td>730</td>
                        <td>51.3%</td>
                        <td>0.83</td>
                    </tr>
                    <tr>
                        <td>Neutral</td>
                        <td>390</td>
                        <td>27.9%</td>
                        <td>0.00</td>
                    </tr>
                    <tr>
                        <td>Negative</td>
                        <td>296</td>
                        <td>20.8%</td>
                        <td>-0.71</td>
                    </tr>
                </tbody>
            </table>

            <h3>What Surprised Me</h3>
            <p>We initially predicted that positive and negative reviews would show very clear, cleanly separated patterns of trauma language, but the data revealed more overlap than expected. Some positive reviews still used words associated with fear or distress, while some negative reviews included moments of reflection or empowerment. This challenged my understanding by showing that emotional processing in horror does not have two parts. Viewers do not simply feel ‚Äúgood‚Äù or ‚Äúbad‚Äù‚Äîthey often experience trauma, fear, and empowerment simultaneously, and their language reflects that complexity.</p>
        </section>

        <section id="reflection">
            <h2>Critical Reflection</h2>
            <!-- TODO: Connect to course frameworks -->

            <p>This project demonstrates what happens when coding meets culture by revealing insights that neither computational analysis nor traditional close reading could discover alone. The computational methods allowed us to identify large-scale emotional and trauma-related patterns across hundreds of reviews, while close reading helped interpret the cultural meaning behind those patterns. 
            What strengthened this project even more was how directly it connected to our course work. Throughout the semester, we explored how texts gain meaning not only through their content but through the communities that interact with them. The project showed that digital humanities tools do not replace interpretation; they expand it, enabling us to see emotional and cultural structures that align with theories we have studied about trauma, memory, audience reception, and participatory culture. 
            </p>

            <h3>Integration of Methods</h3>
            <p><strong>What computational methods revealed:</strong> The computational analysis uncovered broad emotional patterns that only emerge at scale for example, the clustering of empowerment words (‚Äúface,‚Äù ‚Äústrong,‚Äù ‚Äúovercome‚Äù) with positive sentiment and distress-oriented trauma terms (‚Äútriggered,‚Äù ‚Äúdisturbing,‚Äù ‚Äúpanic‚Äù) with negative sentiment. Although these words were not necessarily frequent, they were important in helping round our analysis. It also revealed multi-topic connections between personal trauma language and plot discussion, showing that reviewers frequently blend interpretation of the film with autobiographical reflection. These trends would be nearly impossible to see through reading a handful of reviews. </p>
            <p><strong>What close reading added:</strong> Close reading helped explain why those patterns appeared. By examining specific reviews, it became clear that positive reviewers often described the film as cathartic, framing fear as something they could confront safely. Negative reviewers, however, used trauma language to express unresolved anxieties or discomfort with the film‚Äôs content. The interpretive work added variation showing that horror reviews function as a space for identity, memory, and emotional processing, not just reaction. Close reading transformed the computational patterns from abstract data points into culturally meaningful insights about how people use horror to navigate trauma.</p>

            <div class="framework-callout">
                <h3>üìê Classification Logic</h3>
                <p>This project connects to <strong>Classification Logic</strong> by revealing how algorithmic categorization shapes our understanding of how reviewers use emotional language to process trauma. By applying computational methods such as sentiment analysis, topic modeling, and term-frequency analysis, the project demonstrates how algorithms sort, cluster, and label complex human expressions into discrete emotional categories. This mirrors the broader logic of classification systems, which simplify nuanced experiences like trauma‚Äîinto data-driven groupings. In doing so, the project exposes both the power and the limitations of these classificatory frameworks, showing how algorithmic structures can illuminate patterns in emotional expression while also potentially flattening or constraining the depth of individual traumatic narratives. </p>

                <p><em>Critical question:</em> Reducing complex cultural expressions to computational categories inevitably strips away key nuances. Algorithms often overlook the contextual, historical, and social meanings that shape how communities communicate, flattening subtle forms of tone, symbolism, and emotion into rigid labels. They also erase intra-group diversity and obscure the power dynamics that influence whose voices are represented and how. As a result, the rich layers of lived experience‚Äîirony, ambivalence, cultural memory, and aesthetic form are reduced to simplified outputs that can illuminate broad patterns but risk misrepresenting the depth and complexity of the expressions themselves.</p>
            </div>

            <div class="framework-callout">
                <h3>ü§ñ AI Agency</h3>
                <p>The use of topic modeling and sentiment analysis demonstrates <strong>AI Agency</strong> concerns. While the algorithms appear to "discover" meaning, the interpretation and framing of results remains entirely human. These tools only surface statistical patterns; they do not understand cultural context, emotional nuance, or authorial intent. Any sense of agency we attribute to the AI is actually a projection of our own analytical choices‚Äîwhat data we select, how we preprocess it, which parameters we set, and how we decide to label or narrate the outputs. In this way, the seeming objectivity of algorithmic insights can mask the deeply subjective human decisions guiding them, raising important questions about where meaning truly comes from and who (or what) we credit with producing it.</p>
            </div>

            <h3>Limitations & Future Directions</h3>
            <p><strong>What I would do differently:</strong> We would take more time to find data while also taking time tod design our website. We waited until the last minute and we agreed it could have been easier if we started working more before Thanksgiving break. Our work that was done is good, just rushed to be finished</p>
            <p><strong>Questions that remain:</strong> I think we answered majority of questions that we had about this topic. everything was very clear and laid out nice especially when it came to processing the data we picked. We would say we wonder how the IT movie reviews relates or contrasts with other horror movie reviews or trauma-related media. We think this could be very informative to the topic at hand and provide more insight to the movie reviews of IT.</p>
            <p><strong>Confidence in conclusions:</strong> [We are condifent in our findings because of the in-depth work we did to analysis and describe the data. The only caveat to this data is that it is only coming from one movie rather than multiple so the data of trauma healing with horror movies might differ. Overall, the dataset was big which makes us more confident in the work we did.</p>
        </section>
    </main>

    <footer>
        <p>üìä <strong>Project Materials:</strong>
            <a href="https://github.com/yourusername/project-name">View Google Colab Notebooks & Data on GitHub</a>
        </p>
        <p>&copy; 2025 Lucy Fulghum and Reagan Nowak | WRIT 20833: Introduction to Coding in the Humanities</p>
    </footer>
</body>
</html>
